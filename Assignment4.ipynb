{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Deep learning and unsupervised learning\n",
    "For this assignment you are allowed to use data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "Pick any image based dataset from the list, implement the preprocessing and justify the preprocessing steps, extract features and justify the methods used, select features and justify the methods used. Some of this is done already in one of the previous assignments. You can reuse\n",
    "things.\n",
    "\n",
    "- [] Implement (using the selected features) one basic machine learning algorithm for classification and justify your choice 20 (without justification 10).\n",
    "\n",
    "- [] Implement (using the selected features) one advanced machine learning algorithm for classification and justify your choice 20 (without justification 10).\n",
    "\n",
    "- [] Implement a CNN with hyperparameter tuning (for this you can directly use the data after the preprocessing) (30)\n",
    "\n",
    "- [] Compare and Explain the results in terms of both the computation time and the performance of the classification algorithms. (30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing, extract features, select features.\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define paths and parameters\n",
    "dataset_path = \"image_dataset\"\n",
    "preprocessed_path = \"preprocessed_arrays\"\n",
    "image_size = (224, 224)  # Image size\n",
    "class_names = [\"hatchback\", \"motorcycle\", \"pickup\", \"sedan\", \"suv\"]\n",
    "\n",
    "# Create directory to save preprocessed arrays\n",
    "os.makedirs(preprocessed_path, exist_ok=True)\n",
    "\n",
    "def preprocess_image(img):\n",
    "    \"\"\"\n",
    "    Preprocess the image: convert to grayscale, resize, and normalize.\n",
    "    \"\"\"\n",
    "    # Step 1: Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Step 2: Resize the image\n",
    "    img_resized = cv2.resize(gray, image_size)\n",
    "    # Step 3: Normalize the image\n",
    "    img_normalized = img_resized / 255.0\n",
    "    return img_normalized\n",
    "\n",
    "# Preprocess images and save as NumPy arrays\n",
    "for class_name in class_names:\n",
    "    folder_path = os.path.join(dataset_path, class_name)\n",
    "    class_output_path = os.path.join(preprocessed_path, class_name)\n",
    "    os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder not found: {folder_path}\")\n",
    "        continue\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            try:\n",
    "                # Read and preprocess the image\n",
    "                img = cv2.imread(file_path)\n",
    "                img_preprocessed = preprocess_image(img)\n",
    "\n",
    "                # Save the preprocessed image as a NumPy array\n",
    "                save_path = os.path.join(class_output_path, file_name.split('.')[0] + \".npy\")\n",
    "                np.save(save_path, img_preprocessed)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "print(f\"Preprocessing completed. Preprocessed arrays saved in '{preprocessed_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "# Define paths\n",
    "edge_detected_path = \"edge_detected_arrays\"\n",
    "\n",
    "# Create directory to save edge-detected arrays\n",
    "os.makedirs(edge_detected_path, exist_ok=True)\n",
    "\n",
    "def apply_edge_detection(img):\n",
    "    \"\"\"\n",
    "    Apply edge detection to a preprocessed image (already in grayscale).\n",
    "    \"\"\"\n",
    "    # Apply Gaussian Blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    # Apply Canny Edge Detection\n",
    "    edges = cv2.Canny((blurred * 255).astype(np.uint8), threshold1=50, threshold2=150)\n",
    "    return edges / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "# Perform edge detection and save as NumPy arrays\n",
    "for class_name in class_names:\n",
    "    class_input_path = os.path.join(preprocessed_path, class_name)\n",
    "    class_output_path = os.path.join(edge_detected_path, class_name)\n",
    "    os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(class_input_path):\n",
    "        print(f\"Folder not found: {class_input_path}\")\n",
    "        continue\n",
    "\n",
    "    for file_name in os.listdir(class_input_path):\n",
    "        file_path = os.path.join(class_input_path, file_name)\n",
    "\n",
    "        if file_name.lower().endswith('.npy'):\n",
    "            try:\n",
    "                # Load the preprocessed image as a NumPy array\n",
    "                img_preprocessed = np.load(file_path)\n",
    "                # Apply edge detection\n",
    "                img_edges = apply_edge_detection(img_preprocessed)\n",
    "\n",
    "                # Save the edge-detected image as a NumPy array\n",
    "                save_path = os.path.join(class_output_path, file_name)\n",
    "                np.save(save_path, img_edges)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "print(f\"Edge detection completed. Edge-detected arrays saved in '{edge_detected_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define paths\n",
    "preprocessed_path = \"edge_detected_arrays\"\n",
    "feature_selected_path = \"feature_selected_arrays\"\n",
    "\n",
    "# Create directory to save feature-selected arrays\n",
    "os.makedirs(feature_selected_path, exist_ok=True)\n",
    "\n",
    "# Load preprocessed data\n",
    "X = []  # Feature data\n",
    "y = []  # Labels\n",
    "\n",
    "for class_name in sorted(os.listdir(preprocessed_path)):  # Sort class directories\n",
    "    class_input_path = os.path.join(preprocessed_path, class_name)\n",
    "\n",
    "    if not os.path.exists(class_input_path):\n",
    "        print(f\"Folder not found: {class_input_path}\")\n",
    "        continue\n",
    "\n",
    "    for file_name in sorted(os.listdir(class_input_path)):  # Sort files within each class\n",
    "        if file_name.lower().endswith('.npy'):\n",
    "            try:\n",
    "                # Load preprocessed image\n",
    "                file_path = os.path.join(class_input_path, file_name)\n",
    "                img_array = np.load(file_path).flatten()  # Flatten image array\n",
    "                X.append(img_array)\n",
    "                y.append(class_name)  # Add corresponding class label\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading file {file_path}: {e}\")\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "image_data_reduced = pca.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_data_reduced, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Basic Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Advanced Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a CNN with hyperparameter tuning (use data directly after preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "Pick any dataset from the list, implement the preprocessing and justify the preprocessing steps, extract features and justify the methods used, select features and justify the methods used. Some of this is done already in one of the previous assignments. You can reuse things.\n",
    "\n",
    "Implement three clustering methods out of the following and justify your choices (30)\n",
    "\n",
    "- K-means\n",
    "- Hierarchical Clustering\n",
    "- Fuzzy-C-means\n",
    "- DBSCAN\n",
    "- Gaussian mixture models\n",
    "- Self-organizing maps\n",
    "\n",
    "Compare and Explain the results (30)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing, extract features, select features. (Can reuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement cluster method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement cluster method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement cluster method 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
